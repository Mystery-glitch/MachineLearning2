


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.optim as optim
import cv2

from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report

from PIL import Image
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms





device=torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print("Using device:",device)





transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

dataset = datasets.ImageFolder(r"D:\cell_images", transform=transform)
classes = dataset.classes
print("Classes: ", classes)





train = int((0.8) * len(dataset))
test = len(dataset) - train
trainDataset, testDataset = random_split(dataset, [train, test])

trainLoader = DataLoader(trainDataset, batch_size=128, shuffle=True)
testLoader = DataLoader(testDataset, batch_size=128, shuffle=False)





# train = int(0.1 * len(dataset))  # use only 10% for training
# test = int(0.02 * len(dataset))  # use 2% for testing
# trainDataset, _ = random_split(dataset, [train, len(dataset)-train])
# testDataset, _ = random_split(dataset, [test, len(dataset)-test])

# trainLoader = DataLoader(trainDataset, batch_size=128, shuffle=True)
# testLoader = DataLoader(testDataset, batch_size=128, shuffle=True)





images, labels = next(iter(trainLoader))
plt.figure(figsize=(5,5))

for i in range(9):
    img = images[i].permute(1,2,0)
    img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])
    img = torch.clamp(img, 0, 1)
    plt.subplot(3, 3, i+1, xticks=[], yticks=[])
    plt.imshow(img)
    plt.title(classes[labels[i]])

plt.tight_layout()
plt.show()





# Min-Max Normalization
for images, labels in trainLoader:
    imagesMin = images.min()
    imagesMax = images.max()
    minMax = (images - imagesMin) / (imagesMax - imagesMin)
    print("After Min-Max Normalization: ", minMax.shape)
    break

# Z-Score Normalization
for images, labels in trainLoader:
    mean = images.mean()
    std = images.std()
    zScore = (images - mean) / std
    print("After Z-Score Normalization: ", zScore.shape)
    break





class simpleCNN(nn.Module):
    def __init__(self, numClasses=2):
        super(simpleCNN, self).__init__()

        # Layer1: BatchNorm
        self.layer1 = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(2,2)
        )

        # Layer2: LayerNorm
        self.layer2 = nn.Sequential(
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.LayerNorm([32, 64, 64]),
            nn.ReLU(),
            nn.MaxPool2d(2,2)
        )

        self.fc = nn.Linear(32*32*32, numClasses)

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

model = simpleCNN(numClasses=len(classes)).to(device)
print(model)


for images, labels in trainLoader:
    images = images.to(device)
    outputs = model(images)
    print("Output shape after CNN:", outputs.shape)
    break





criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
numEpochs = 5


trainLosses = []
valAccuracies = []

for epoch in range(numEpochs):
    model.train()
    totalLoss = 0

    for inputs, labels in trainLoader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()              # reset gradients
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()                    # backpropagation
        optimizer.step()                   # update weights

        totalLoss += loss.item()
    
    avgLoss = totalLoss / len(trainLoader)
    trainLosses.append(avgLoss)
    print(f"Epoch [{epoch+1}/{numEpochs}], Loss: {avgLoss: .4f}")

    # Validation accuracy after each epoch
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for i, (inputs, labels) in enumerate(testLoader):
            if i >= 5:
                break
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    accuracy = 100 * correct / total
    valAccuracies.append(accuracy)
    print(f"Validation Accuracy: {accuracy: .2f}%")
    





plt.figure(figsize=(8,4))

plt.subplot(1,2,1)
plt.plot(range(1, numEpochs+1), trainLosses, marker='o', label='Training Loss')
plt.title("Training Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.grid()
plt.legend()

plt.subplot(1,2,2)
plt.plot(range(1, numEpochs+1), valAccuracies, marker='o', color='orange', label= 'Validation Accuracy')
plt.title("Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.grid()
plt.legend()

plt.tight_layout()
plt.show()





model.eval()
yTrue, yPredict = [], []

with torch.no_grad():
    for inputs, labels in testLoader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        yTrue.extend(labels.cpu().numpy())
        yPredict.extend(predicted.cpu().numpy())

testAccuracy = accuracy_score(yTrue, yPredict)
print(f"Final Test Accuracy: {testAccuracy * 100:.2f}%")





cm = confusion_matrix(yTrue, yPredict)
display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)
display.plot(cmap='Blues', xticks_rotation=45)
plt.title("Confusion Matrix")
plt.show()





images, labels = next(iter(testLoader))
images, labels = images.to(device), labels.to(device)
outputs = model(images)
_, predicted = torch.max(outputs, 1)

plt.figure(figsize=(6,6))
for i in range(9):
    img = images[i].cpu().permute(1,2,0)
    img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])
    img = torch.clamp(img, 0, 1)
    plt.subplot(3, 3, i+1)
    plt.imshow(img)
    plt.title(f"Pred: {classes[predicted[i]]}\nTrue: {classes[labels[i]]}")
    plt.axis("off")

plt.tight_layout()
plt.show()
